{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 匯入訓練與測試資料 import dataset\n",
    "data_path = 'D:\\\\Users\\\\Qoo\\\\Desktop\\\\taipower\\\\data\\\\'\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path+ 'submit.csv')\n",
    "\n",
    "# merge train and test data\n",
    "df = pd.merge(train,test,how='inner',\n",
    "        on=['CityName','TownName','VilName','VilCode'])\n",
    "\n",
    "#transpose columns to rows\n",
    "var_names = list(df.columns)\n",
    "df2 = pd.melt(df,id_vars=['CityName','TownName','VilName','VilCode'],value_vars=var_names[4:len(var_names)],\n",
    "              var_name='typhoon',value_name='elect_down')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of typhoon : 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MERANTIANDMALAKAS', 'NESATANDHAITANG'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 颱風警報資料庫 http://rdc28.cwb.gov.tw/TDB/ntdb/pageControl/ty_warning\n",
    "typhoon = pd.read_csv(data_path + 'typhoon_alert.csv',encoding='big5')\n",
    "#取出颱風警報時間 方法來源 https://opensourcehacker.com/2011/02/23/tuplifying-a-list-or-pairs-in-python/\n",
    "i = iter(list(typhoon.duration))\n",
    "duration = zip(i,i)\n",
    "typhoon_time = pd.DataFrame(duration, columns=['arrive','leave'])\n",
    "\n",
    "#合併颱風資料與警報時間\n",
    "cols = list(typhoon)\n",
    "cols.remove('duration')\n",
    "tp = typhoon.loc[0:len(typhoon):2,cols]\n",
    "tp = tp.reset_index(drop=True)\n",
    "tp2 = pd.concat([tp,typhoon_time],axis=1,join_axes=[tp.index])\n",
    "\n",
    "#取出訓練與預測資料的時間區間\n",
    "tp2.arrive = pd.to_datetime(tp2.arrive)\n",
    "tp2.leave = pd.to_datetime(tp2.leave)\n",
    "tp2.year = tp2.arrive.dt.year\n",
    "mask = (tp2.year >=2014) & (tp2.year<=2017)\n",
    "tp3 = tp2[mask]\n",
    "#取出的颱風總數\n",
    "print 'total number of typhoon : %s' %len(tp3)\n",
    "\n",
    "#找出颱風資料庫尚未有的颱風資料\n",
    "set(df2.typhoon.str.upper()) - set(tp3.en_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# MERANTIANDMALAKAS\n",
    "MERANTIANDMALAKAS = tp3.loc[(tp3.en_name =='MALAKAS') | (tp3.en_name =='MERANTI'),]\n",
    "#print MERANTIANDMALAKAS\n",
    "tp3.loc[19,6:11] = MERANTIANDMALAKAS.iloc[:,6:11].astype(np.int16).max()\n",
    "tp3.iloc[19,[0,1,2,3,4,5,11,12]] = [2016,201615,u'莫蘭蒂及馬勒卡',u'MERANTIANDMALAKAS','7',u'強烈',pd.to_datetime('2016-09-12 23:30:00'),pd.to_datetime('2016-09-18 08:30')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NESATANDHAITANG\n",
    "NESATANDHAITANG = tp3.loc[(tp3.en_name =='NESAT') | (tp3.en_name =='HAITANG'),]\n",
    "#print NESATANDHAITANG\n",
    "tp3.loc[20,6:11] = NESATANDHAITANG.iloc[:,[6,7,8,10]].astype(np.int16).max()\n",
    "tp3.iloc[20,[0,1,2,3,4,5,9,11,12]] = [2017,201711,u'尼莎及海棠',u'NESATANDHAITANG','---',u'中度',60,pd.to_datetime('2017-07-28 08:30'),pd.to_datetime('2017-07-31 08:30')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.typhoon = df2.typhoon.str.upper()\n",
    "df3 = pd.merge(df2, tp3, how='left',left_on='typhoon', right_on='en_name' )\n",
    "print len(df3)\n",
    "\n",
    "#檢查是否已經蒐集到全部的颱風資料\n",
    "set(df2.typhoon.str.upper()) - set(tp3.en_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中度    39255\n",
      "強烈    23553\n",
      "輕度    15702\n",
      "Name: magnitude, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# r10_km\n",
    "df3.loc[df3.r10_km =='---','r10_km'] = '0'\n",
    "\n",
    "#typhoon type\n",
    "df3.loc[df3.type ==u'---','type'] = 0\n",
    "df3.loc[df3.type ==u'特殊','type'] = 10\n",
    "\n",
    "#typhoon magnitude\n",
    "print df3.magnitude.value_counts()\n",
    "df3.loc[df3.magnitude ==u'輕度','magnitude'] = 1\n",
    "df3.loc[df3.magnitude ==u'中度','magnitude'] = 2\n",
    "df3.loc[df3.magnitude ==u'強烈','magnitude'] = 3\n",
    "\n",
    "# time-related variables\n",
    "# arrive \n",
    "df3.loc[:,'arrive_month'] = df3.arrive.dt.month\n",
    "df3.loc[:,'arrive_hour'] = df3.arrive.dt.hour\n",
    "df3.loc[:,'arrive_weekday'] = df3.arrive.dt.weekday\n",
    "df3.loc[:,'arrive_week'] = df3.arrive.dt.week\n",
    "df3.loc[:,'duration'] = df3.leave - df3.arrive\n",
    "df3.loc[:,'duration_h'] = df3.duration.dt.total_seconds() / 3600\n",
    "\n",
    "#處理變數型態\n",
    "df3.year = df3.year.astype('float')\n",
    "df3.hpa = df3.hpa.astype('float')\n",
    "df3.wind_speed = df3.wind_speed.astype('float')\n",
    "df3.r7_km = df3.r7_km.astype('float')\n",
    "df3.r10_km = df3.r10_km.astype('float')\n",
    "df3.alert_level = df3.alert_level.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checking file's encode\n",
    "all_files = glob.glob(os.path.join(data_path+'poledata/','*.csv'))\n",
    "for file in all_files:\n",
    "    try:\n",
    "        pd.read_csv(file,encoding='utf-8',usecols=[0,1,2,3])\n",
    "    except:\n",
    "        print 'error at %s' %file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files number : 24\n"
     ]
    }
   ],
   "source": [
    "# import multiple electric pole dataset\n",
    "print 'total files number : %s' %len(glob.glob(os.path.join(data_path+'poledata/','*.csv')))\n",
    "pole = pd.concat(pd.read_csv(file,encoding='utf-8',usecols=[0,1,2,3,4]) for file in all_files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are god-damn right!\n"
     ]
    }
   ],
   "source": [
    "#檢查總資料筆數是否有誤\n",
    "L =[]\n",
    "for file in all_files:\n",
    "    L.append(len(pd.read_csv(file,encoding='utf-8',usecols=[0])))\n",
    "if len(pole) == sum(L):\n",
    "    print 'you are god-damn right!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CityName</th>\n",
       "      <th>TownName</th>\n",
       "      <th>VilName</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>p_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>新北市</td>\n",
       "      <td>三芝區</td>\n",
       "      <td>福德里</td>\n",
       "      <td>B6281EC17</td>\n",
       "      <td>水泥桿</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CityName TownName VilName coordinate p_type\n",
       "0      新北市      三芝區     福德里  B6281EC17    水泥桿"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename dataframe\n",
    "old_names = list(pole.columns)\n",
    "new_names = ['CityName','TownName','VilName','coordinate','p_type']\n",
    "pole.rename(columns=dict(zip(old_names,new_names)),inplace=True)\n",
    "pole.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "#pole.groupby(['CityName','TownName','VilName'],as_index=False).count()\n",
    "#每個村里有幾類桿子\n",
    "p1 = pole.groupby(['CityName','TownName','VilName'],as_index=False).agg({'p_type':'nunique'})\n",
    "p1.columns.values[3] = 'pole_type_counts'\n",
    "p1.CityName = p1.CityName.replace({u'臺':u'台'},regex=True)\n",
    "#每個村里下,各類桿子有幾支\n",
    "p2 = pole.groupby(['CityName','TownName','VilName','p_type'],as_index=False).count()\n",
    "p2 = p2.pivot_table(index=['CityName','TownName','VilName'],columns='p_type',values='coordinate')\n",
    "p2 = p2.reset_index()\n",
    "p2 = p2.fillna(0)\n",
    "p2.columns.values[3:13] =['p%s' % s for s in range(1,11)] \n",
    "p2.CityName = p2.CityName.replace({u'臺':u'台'},regex=True)\n",
    "# or ['p{}'.format(i) for i in range(1,11)]\n",
    "#每個村里總共幾支\n",
    "p3 = pole.groupby(['CityName','TownName','VilName'],as_index=False).count()\n",
    "p3.columns.values[3] = 'pole_counts'\n",
    "p3 = p3.iloc[:,[0,1,2,3]]\n",
    "p3.CityName = p3.CityName.replace({u'臺':u'台'},regex=True)\n",
    "\n",
    "#transform columns value from unicode to str\n",
    "for data in [p1,p2,p3]:\n",
    "    for column in ['CityName','TownName','VilName']:\n",
    "        data[column] =  data[column].str.encode('utf-8')\n",
    "#double check encoding\n",
    "print type(df3.CityName[1])\n",
    "print type(p1.CityName[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.CityName = df3.CityName.replace({'臺':'台'},regex=True)\n",
    "df3 = pd.merge(df3,p1,how='left',on=['CityName','TownName','VilName'])\n",
    "df3 = pd.merge(df3,p2,how='left',on=['CityName','TownName','VilName'])\n",
    "df3 = pd.merge(df3,p3,how='left',on=['CityName','TownName','VilName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#電桿資料並未包含全部村里 (需要補值)\n",
    "df3 = df3.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#是否為雙颱\n",
    "df3['double_kill'] = 0\n",
    "df3.loc[(df3.typhoon =='NESATANDHAITANG')|(df3.typhoon =='MERANTIANDMALAKAS'),'double_kill'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#各鄉鎮市區人口密度 https://data.gov.tw/dataset/8410\n",
    "pop_files = glob.glob(os.path.join(data_path+'population/','*.csv'))\n",
    "population = pd.concat(pd.read_csv(d, skiprows=2, nrows=370, names=['Minguo_year','location',\n",
    "            'people_total','area','population_density'] ) for d in pop_files)\n",
    "population['CityName'] = population.location.str.slice(0,9)\n",
    "population['TownName'] = population.location.str.slice(9,)\n",
    "\n",
    "#處理行政區升格問題\n",
    "population.CityName = population.CityName.replace({'臺':'台'},regex=True)\n",
    "population.TownName = population.TownName.replace({'員林鎮':'員林市'},regex=True)\n",
    "population.TownName = population.TownName.replace({'頭份鎮':'頭份市'},regex=True)\n",
    "\n",
    "#西元轉民國,以方便合併資料\n",
    "df3.loc[df3.year == 2017,'Minguo_year'] =105\n",
    "df3.loc[df3.year == 2016,'Minguo_year'] =105\n",
    "df3.loc[df3.year == 2015,'Minguo_year'] =104\n",
    "df3.loc[df3.year == 2014,'Minguo_year'] =103\n",
    "df3.loc[df3.year == 2013,'Minguo_year'] =102\n",
    "df3 = pd.merge(df3, population, how='left',on=['CityName','TownName','Minguo_year'] )\n",
    "\n",
    "#City_dummy = pd.get_dummies(df3['CityName'])\n",
    "#City_dummy.columns.values[0:22] =['c%s' % s for s in range(1,23)] \n",
    "#df3 = pd.concat([df3,City_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.to_csv('D:/Users/Qoo/Desktop/df.csv',index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
